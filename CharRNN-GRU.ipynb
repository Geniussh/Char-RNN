{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 5569684\n",
      "All possible characters: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n",
      "Number of all possible characters: 100\n"
     ]
    }
   ],
   "source": [
    "all_chars = string.printable\n",
    "n_chars   = len(all_chars)\n",
    "file      = open('./trump.txt', encoding=\"utf-8\").read()\n",
    "file_len  = len(file)\n",
    "\n",
    "print('Length of file: {}'.format(file_len))\n",
    "print('All possible characters: {}'.format(all_chars))\n",
    "print('Number of all possible characters: {}'.format(n_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning a string into a tensor.\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        try:\n",
    "            tensor[c] = all_chars.index(string[c])\n",
    "        except:\n",
    "            continue\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_set(seq_len, batch_size):\n",
    "    input = torch.LongTensor(batch_size, seq_len)\n",
    "    target = torch.LongTensor(batch_size, seq_len)\n",
    "    for i in range(batch_size):\n",
    "        start_index  = random.randint(0, file_len - seq_len - 1)\n",
    "        end_index    = start_index + seq_len + 1\n",
    "        seq          = file[start_index:end_index]\n",
    "        input[i]     = char_tensor(seq[:-1])\n",
    "        target[i]    = char_tensor(seq[1:])\n",
    "    input  = Variable(input)   # Wrap up the tensor to backpropagate a loss function\n",
    "    target = Variable(target)  # Wrap up the tensor to backpropagate a loss function\n",
    "    if torch.cuda.is_available():\n",
    "        input  = input.cuda()\n",
    "        target = target.cuda()\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class charRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model='gru', n_layers=1):\n",
    "        # Initialization.\n",
    "        super(charRNN, self).__init__()\n",
    "        self.model = model.lower()\n",
    "        self.input_size  = input_size        # Input size: Number of unique chars.\n",
    "        self.hidden_size = hidden_size       # Hidden size: 100.\n",
    "        self.output_size = output_size       # Output size: Number of unique chars.\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Use Word Embeddings to encode semantic similarity in words instead of one-hot\n",
    "        self.embeds = nn.Embedding(input_size, hidden_size)\n",
    "        if self.model == \"rnn\":\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, n_layers)\n",
    "        elif self.model == \"gru\":\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        elif self.model == \"lstm\":\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # Forward function.\n",
    "        batch_size = input.size(0)\n",
    "        encoded = self.embeds(input)\n",
    "        output, hidden = self.rnn(encoded.view(1, batch_size, -1), hidden)\n",
    "        output = self.decoder(output.view(batch_size, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def forward2(self, input, hidden):\n",
    "        encoded = self.embeds(input.view(1, -1))\n",
    "        output, hidden = self.rnn(encoded.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initial hidden state.\n",
    "        if self.model == \"lstm\":\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size)))\n",
    "        return Variable(torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(net, opt, input, target):\n",
    "    hidden = net.init_hidden(batch_size) # Initial hidden state.\n",
    "    if torch.cuda.is_available():\n",
    "        hidden = hidden.cuda()     \n",
    "    net.zero_grad()                      # Clear the gradient.\n",
    "    loss = 0                             # Initial loss.\n",
    "    \n",
    "    for t in range(seq_len):            # For each one in the input sequence.\n",
    "        output, hidden = net(input[:,t], hidden)\n",
    "        loss += loss_func(output.view(batch_size, -1), target[:,t])\n",
    "        \n",
    "    loss.backward()                      # Backward. \n",
    "    opt.step()                           # Update the weights.\n",
    "    \n",
    "    return loss / seq_len       # Return the average loss w.r.t sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(net, init_seq='W', predicted_len=100):\n",
    "    # Initialize the hidden state, input and the predicted sequence.\n",
    "    hidden = net.init_hidden(1)\n",
    "    init_input = Variable(char_tensor(init_seq).unsqueeze(0))\n",
    "    if torch.cuda.is_available():\n",
    "        hidden = hidden.cuda()\n",
    "        init_input = init_input.cuda()\n",
    "    predicted_seq = init_seq\n",
    "    \n",
    "    # Use initial string to \"build up\" hidden state.\n",
    "    for t in range(len(init_seq) - 1):\n",
    "        _, hidden = net(init_input[:,t], hidden)\n",
    "    \n",
    "    # Set current input as the last character of the initial string.\n",
    "    input = init_input[:,-1]\n",
    "    \n",
    "    # Predict more characters after the initial string.\n",
    "    for t in range(predicted_len):\n",
    "        # Get the current output and hidden state.\n",
    "        output, hidden = net(input, hidden)\n",
    "        \n",
    "        # Sample from the output as a multinomial distribution.\n",
    "        predicted_index = torch.multinomial(output.data.view(-1).exp(), 1)[0]\n",
    "        \n",
    "        # Add predicted character to the sequence\n",
    "        predicted_char = all_chars[predicted_index]\n",
    "        predicted_seq += predicted_char\n",
    "        \n",
    "        # Use the predicted character to generate the input of next round.\n",
    "        input = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "    \n",
    "    return predicted_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:99/2000 loss:2.6147594451904297\n",
      "generated sequence: Wresterwave to just prodess turn-tendepnterolefdansjod at he consill yeatter, are to loatnounnevels t\n",
      "\n",
      "iter:199/2000 loss:1.8587360382080078\n",
      "generated sequence: Who has maulfulinos didn but my sall wear pengling....\n",
      "....Someare beans of great onest presidemolled\n",
      "\n",
      "iter:299/2000 loss:1.697770357131958\n",
      "generated sequence: Winne-propoles # TogirationalDonaldjtrump.\n",
      "\" @ Thenro Think Philing loves to @ Wenneprain: We are who\n",
      "\n",
      "iter:399/2000 loss:1.6248397827148438\n",
      "generated sequence: Who fore the exadd the victers- - I EWERNY\" Dollars, but our country. quescoty it beay the turt best.\n",
      "\n",
      "iter:499/2000 loss:1.5894415378570557\n",
      "generated sequence: Wontu what the nexard that this had just brave ltidol8hic is you buildie \"stuckaonster Great!\n",
      "\" @ Sum\n",
      "\n",
      "iter:599/2000 loss:1.5635677576065063\n",
      "generated sequence: We have to welve does you....\n",
      ".....wert @ ApprenticeBrest of Trty Defense Jown UNAUNE Kuclear Clin Do\n",
      "\n",
      "iter:699/2000 loss:1.54121994972229\n",
      "generated sequence: WPOSR_AndObama's history. NO WALK! Thank you as all of Thucks.\n",
      "Jiveappends, does @ Chiling, Pend 0Doi\n",
      "\n",
      "iter:799/2000 loss:1.5300995111465454\n",
      "generated sequence: Washing 10 minute basen so support throuse with couldn0s very wetweessed, business to 0Bliker really \n",
      "\n",
      "iter:899/2000 loss:1.5211281776428223\n",
      "generated sequence: Wether torigo, 0MangerAfol is back to be incompeted to started with the people https://www.donaldjtru\n",
      "\n",
      "iter:999/2000 loss:1.5152512788772583\n",
      "generated sequence: WRExIDDoSvASAST 0 for ClOpay Virger, testimes.\n",
      "Great Ragatuies are Mich Noot the has the accounsment \n",
      "\n",
      "iter:1099/2000 loss:1.5092536211013794\n",
      "generated sequence: WHRLPPC \"\n",
      "\"Greens lowest nothing in @ Stecking AM job.\" Brene.\n",
      "\" @ M7Mudlem: @ realDonaldTrump Winner\n",
      "\n",
      "iter:1199/2000 loss:1.502633810043335\n",
      "generated sequence: Windal GreenlDusi Court President Time Campaign incompetent to gle, nevery, but it. Keered ago they a\n",
      "\n",
      "iter:1299/2000 loss:1.4962258338928223\n",
      "generated sequence: What I little supposed the Democrats Ebolo.\n",
      "Entreplays not ask The AvericaGlives mucocicthelved in th\n",
      "\n",
      "iter:1399/2000 loss:1.4904416799545288\n",
      "generated sequence: WRUSHDIRASI 0AMever Trump0s businessional supporting, suricar created the Trust cover of mondader0: N\n",
      "\n",
      "iter:1499/2000 loss:1.4862743616104126\n",
      "generated sequence: What standliving & this the BaSews would # ITS is been why done in your twitter in 27 base from . I t\n",
      "\n",
      "iter:1599/2000 loss:1.4850879907608032\n",
      "generated sequence: Wisgaches.phafre.nighing. Thank you DTALAASt WALL!https://www.facebecold_nookedgage.com/trump- Venize\n",
      "\n",
      "iter:1699/2000 loss:1.4835196733474731\n",
      "generated sequence: WHORN\n",
      "Lot and ever breaking tood suparency. Bling is say far really. Corwed was highing better...\" Th\n",
      "\n",
      "iter:1799/2000 loss:1.4753597974777222\n",
      "generated sequence: White Hat. We are student!\n",
      "Can't wait to prevent that. If Trump staminated by will sure pleasa to fix\n",
      "\n",
      "iter:1899/2000 loss:1.4784338474273682\n",
      "generated sequence: Wayge Nancy Politics Agrez. Doculate is luck so who is all heting immigrative!\n",
      "Trial Heriousreay Whit\n",
      "\n",
      "iter:1999/2000 loss:1.4781779050827026\n",
      "generated sequence: Wornsous continues must straight time. Lettered Sir! # Dephabe_Peal Ricans are beauticket would use h\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq_len = 200\n",
    "batch_size = 100\n",
    "hidden_size = 100\n",
    "learning_rate = 0.01\n",
    "iters = 2000  # Number of training iterations.\n",
    "print_iters = 100    # Number of iterations for each log printing.\n",
    "\n",
    "# The loss variables.\n",
    "all_losses = []\n",
    "loss_sum   = 0\n",
    "\n",
    "# Initialize the netword, optimizer and the loss function.\n",
    "net = charRNN(n_chars, hidden_size, n_chars, model='gru', n_layers=3)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "\n",
    "# Training procedure.\n",
    "for i in range(iters):\n",
    "    input, target = training_set(seq_len, batch_size)\n",
    "    loss = train_step(net, opt, input, target)\n",
    "    loss_sum += loss\n",
    "    \n",
    "    # Print the log.\n",
    "    if i % print_iters == print_iters - 1:\n",
    "        print('iter:{}/{} loss:{}'.format(i, iters, loss_sum / print_iters))\n",
    "        print('generated sequence: {}\\n'.format(eval_step(net)))\n",
    "        \n",
    "        #Track the loss.\n",
    "        all_losses.append(loss_sum / print_iters)\n",
    "        loss_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('iters (x100)')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'gru_loss' (list)\n"
     ]
    }
   ],
   "source": [
    "gru_loss = all_losses\n",
    "%store gru_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call so headly of the Pastors has a turned alonies proud, whidue, Birda Busines, to talk it to me back for from People (them for Rep.1\n",
      "Cocaled tonight. Beha-attended, support called to made put our Bight. Greatest less for the Bill, Crime, FakeTuer, better! Cabry BurLey SPAIGNING! Thanks that pick!\n",
      "Nortry Buy-0park is creditms exceines elected American 59 day mun record & due to waste that the Syria on and vuclus hard to couvers for @ RevsJRPut his discussies her voting they reform is NYP in the World cathers magn not a of.th. https://bit.ly/196WWp47 Go Democrats are NOT Things\n",
      "\" @ gowdO a grea\n"
     ]
    }
   ],
   "source": [
    "print(eval_step(net, init_seq='C', predicted_len=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save(filename):\n",
    "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
    "    torch.save(net, save_filename)\n",
    "    print('Saved as %s' % save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as LaTeX_GRU.pt\n"
     ]
    }
   ],
   "source": [
    "save(\"LaTeX_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as Shakespeare_GRU.pt\n"
     ]
    }
   ],
   "source": [
    "save(\"Shakespeare_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as Trump_GRU.pt\n"
     ]
    }
   ],
   "source": [
    "save(\"Trump_GRU\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
